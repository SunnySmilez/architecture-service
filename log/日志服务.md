# 日志服务

> 日志用来记录用户操作、系统运行状态等，是系统中的重要组成部分。日志记录的好坏直接关系到系统出现问题时定位的速度，同时通过对日志的观察和分析，可以提前发现系统可能的风险，避免线上事故的发生。

[TOC]

## 日志规范

> 为了方便对日志的查询及聚合, 对日志当中的常用字段进行了统一. 
>
> 另外为了方便日志的解析处理, 推荐日志使用**json**的格式进行记录和传输.

### 应用日志(PHP)

**日志字典**

| 字段            | 说明                |
| ------------- | ----------------- |
| date          | 日志记录时间            |
| x_rid         | 请求ID              |
| server_ip     | 服务器IP             |
| client_ip     | 客户端IP             |
| uri           | 访问路径              |
| params        | 请求参数              |
| exectime      | 执行时间(毫秒)          |
| succ          | 执行结果 succ/fail    |
| retcode       | 返回码  成功为`2000000` |
| retmsg        | 返回信息              |
| error_type    | 错误类型              |
| error_code    | 错误码               |
| error_message | 错误信息              |
| error_trace   | 错误栈信息             |

### Nginx日志

**日志字典**

| 字段           | 说明                 |
| ------------ | ------------------ |
| date         | 日志记录时间             |
| x_rid        | 请求ID               |
| server_ip    | 服务器IP              |
| client_ip    | 客户端IP              |
| domain       | 主机域名               |
| uri          | 访问路径               |
| size         | 请求体大小(字节)          |
| responsetime | 请求响应时间(秒)          |
| upstreamtime | nginx向后端转发请求的时间    |
| upstreamhost | nginx服务器地址         |
| xff          | 客户端真实ip(使用代理时)     |
| referer      | 请求来源               |
| agent        | 用户访问代理(系统信息 浏览器信息) |
| status       | http 状态码           |

### 日志级别

- **ERROR**  该级别的错误需要立刻被处理。当ERROR错误发生时，已经影响了用户的正常访问。
- **WARNING** 该日志表示系统可能出现问题。对于那些目前还不是错误，然而不及时处理也会变为错误的情况，也可以记为WARNING日志。
- **INFO** 该种日志记录系统的正常运行状态，例如某个子系统的初始化，某个请求的成功执行等等。
- **DEBUG** 该级别日志的主要作用是对系统每一步的运行状态进行精确的记录。通过该种日志，可以查看某一个操作每一步的执行过程，可以准确定位是何种操作，何种参数，何种顺序导致了某种错误的发生。
- **STAT** 打点日志, 统计用。如记录用户访问的页面，业务流程中的某个动作等记录到数据仓库，方便后续的统计分析

## 日志记录

### Nginx日志

**配置**

1. 修改nginx的日志格式配置 **/etc/nginx/nginx.conf**

```
log_format json '{"date":"$time_iso8601",'
                '"x_rid":"$request_id",'
                '"client_ip":"$remote_addr",'
                '"server_ip":"$server_addr",'
                '"domain":"$host",'
                '"uri":"$uri",'
                '"size":$body_bytes_sent,'
                '"responsetime":$request_time,'
                '"upstreamtime":"$upstream_response_time",'
                '"upstreamhost":"$upstream_addr",'
                '"xff":"$http_x_forwarded_for",'
                '"referer":"$http_referer",'
                '"agent":"$http_user_agent",'
                '"status":$status}';
```

2. 修改日志输出配置 **/etc/nginx/vhost/demo.conf**

```
#访问日志
access_log syslog:server={日志机ip}:515,facility=local6,tag={app}_info,severity=info json;
#错误日志
error_log syslog:server={日志机ip}:515,facility=local6,tag={app}_error,severity=info;
```

##  日志传输

> Syslog是UNIX系统中提供的一种日志记录方法。通过Syslog, 我们可以把多台机器上的日志收集到统一的日志处理机器上。

### 安装

1. 安装(大部分linux发行版已自带)

   ```shell
   yum install rsyslog
   ```

### 部署

1. 添加配置 **/etc/rsyslog.conf**

   ```yaml
   local7.*					@@{日志机ip}:514 #应用日志 
   local6.*					@@{日志机ip}:515 #nginx日志
   ```

2. 启动 `service rsyslog start`


## 日志队列

> 当日志写入量过大，后方日志处理系统无法及时处理时，就需要引入消息队列缓冲日志，削峰填谷。
>
> Syslog自身也实现了队列来缓冲数据，当日志数据量比较少的情况下，Syslog可以完全支持缓冲日志的需求。当然，使用何种日志队列需要按线上实际情况及日志数据量来决定。

### Redis

Redis是一个开源，内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。当数据量不是十分大的情况下，可以使用Redis作为日志队列。

### Kafka

Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：**以时间复杂度为O(1)的方式提供消息持久化能力，并保证即使对TB级以上数据也能保证常数时间的访问性能**。当数据量过大时，推荐使用Kafka。

## 日志解析

### Logstash安装部署

见[数据统计服务-数据采集](../stat/数据采集.md)

### 日志解析配置

> [日志解析配置参考]()

1. 添加应用日志解析配置 **config/conf.d/app.conf**

```
   input {
           tcp {
               port => '514'
               mode => "server"
               add_field => ["log_type", "app"]
           }
   }                                
   filter {
     	if [log_type] == "app" {
       	   dissect {
               mapping => {
                   "message" => "%{?prefix} : [LOG_PATH:%{log_path}] %{log_content}"
               }
       	   }
       	   json {
               source => "log_content"
           }
           date {
               match => ["date", "yyyy-MM-dd HH:mm:ss"]
               timezone => "Asia/Shanghai"
           }
           mutate {
               remove_field => ["message", "host", "port", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9"] #去掉不必要的数据项
           }
           if [level] == "stat" {
          		grok {
                   match => { 
                       "log_path" => "(?<index>\w+)/\d+/\w+\.\d+\.log"
                   }
               	}
     	   }
     	}
   }
   output {
     if [log_type] == "app" {
       	if [level] == "stat" { #统计日志
       		elasticsearch {
              hosts => ["10.0.4.7:9200", "10.0.4.10:9200", "10.0.4.12:9200"]
              index => "stat-%{index}-%{+YYYYMM}"
              document_type => "%{app}"
              flush_size => 1000 #批量上送数据最大条数 不会超过pipeline.batch.size 默认500
              idle_flush_time => 1 #批量上送数据间隔 默认1s
       		}
       	}else{
          elasticsearch {
           	hosts => ["10.0.4.7:9200", "10.0.4.10:9200", "10.0.4.12:9200"]
           	index => "logstash-app-%{app}-%{+YYYYMMdd}"
           	document_type => "%{level}"
           	flush_size => 1000 #批量上送数据最大条数 不会超过pipeline.batch.size 默认500
           	idle_flush_time => 1 #批量上送数据间隔 默认1s
       	  }
          file {
               path => "/mnt/log2017/logs/app/%{app}/%{log_path}"
               gzip => false #按gzip方式压缩
               flush_interval => 2  #指定刷入间隔(秒数)，0代表实时写入 默认2s
               codec => line {
                      format => "%{log_content}"
              }
          }
       	}
     }
   }
```

2. 添加nginx日志解析配置 **config/conf.d/nginx.conf**

```
   input {
            syslog {
               port => '515'
               add_field => ["log_type", "nginx"]
            }
   }
   filter {
     	if [log_type] == "nginx" {
            dissect {
                mapping => {
                    "program" => "%{app}_%{level}"
                }
            }
           if [level] == "info" {
               json {
              		source => "message"
           	   }
             	dissect {
                   mapping => { 
                       "date" => "%{year}-%{month}-%{day}T%{hour}:%{minute}:%{second}+%{?timezone}"
                   }
               }
               mutate {
                   rename => ["message", "log_content"]
                   remove_field => ["date"]
               }
           }
           if [level] == "error" {
               grok {
                   match => { 
                       "message" => "(?<year>\d+)/(?<month>\d+)/(?<day>\d+)\s(?<hour>\d+):(?<minute>\d+):(?<second>\d+)\s"
                   }
               }
               mutate {
                   rename => ["message", "log_content"]
               }
           }

           mutate {
                   add_field => ["date", "%{year}-%{month}-%{day} %{hour}:%{minute}:%{second}"]
                   add_field => ["log_path", "%{year}%{month}/%{level}.%{year}%{month}%{day}.log"]
                   remove_field => ["message", "program", "host", "port", "year", "month", "day", "hour", "minute", "second"]
           }
           date {
               match => ["date", "yyyy-MM-dd HH:mm:ss"]
               timezone => "Asia/Shanghai"
           }
     	}   
   }
   output {
     	if [log_type] == "nginx" {
            elasticsearch {
                hosts => ["10.0.4.7:9200", "10.0.4.10:9200", "10.0.4.12:9200"]
                index => "logstash-nginx-%{app}-%{+YYYYMMdd}"
                document_type => "%{level}"
                flush_size => 1000 #批量上送数据最大条数 不会超过pipeline.batch.size 默认500
                idle_flush_time => 1 #批量上送数据间隔 默认1s
            }
            file {
                 path => "/mnt/log2017/logs/nginx/%{app}/%{log_path}"
                 gzip => false #按gzip方式压缩
                 flush_interval => 2  #指定刷入间隔(秒数)，0代表实时写入 默认2s
                 codec => line {
                        format => "%{log_content}"
                }
            }
     	}		
   }
```

3. 启动 

   ```shell
   bin/logstash -f config/conf.d -l /var/log/logstash 2>&1 &
   ```

   - -w  指定日志处理的线程数量  默认是 CPU 核数		

## 日志存储

### ES安装部署

见[数据统计服务-数据聚合](../stat/数据聚合.md)

### 调优

待补充 

## 日志可视化

### Kibana安装部署

见[数据统计服务-数据可视化](../stat/数据可视化.md)

### 报表项

**应用**

- 访问量
- 访问分布
- 成功率
- 执行平均时长
- 警告数
- 错误数

**Nginx**

- 访问量
- 访问分布
- 成功率
- 执行平均时长
- 4XX状态数量
- 5XX状态数量

## 日志查看

> 待补充

##  参考资料

> - [ELK](http://kibana.logstash.es/content/)
